{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nlpm Notebook\n",
    "Environment: nlpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "801ef473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjective-Noun pairs:\n",
      "Crappy -> socks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Crappy socks Money wasted Bought to wear with my tieks Don’t stay on feet well\"\n",
    "doc = nlp(text)\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for i in range(len(doc) - 1):\n",
    "    if doc[i].pos_ == \"ADJ\" and doc[i+1].pos_ == \"NOUN\":\n",
    "        pairs.append((doc[i].text, doc[i+1].text))\n",
    "\n",
    "print(\"Adjective-Noun pairs:\")\n",
    "for adj, noun in pairs:\n",
    "    print(f\"{adj} -> {noun}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "486ba929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjective-Noun pairs:\n",
      "inside -> back\n",
      "solid -> depression\n",
      "silver -> depression\n",
      "small -> photo\n",
      "High -> quality\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Input text\n",
    "text = \"I think this locket is really pretty. The inside back is a solid silver depression and the front is a dome that is not solid (knotted). You could use it to store a small photo, lock of hair, etc but I use it when I need to carry medication with me. Closes securely. High quality & very pretty.\"\n",
    "\n",
    "# Process text with spaCy pipeline\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract adjective-noun pairs (形容词修饰名词)\n",
    "pairs = []\n",
    "for token in doc:\n",
    "    # Check if token is adjective and its dependency label is 'amod'\n",
    "    if token.pos_ == \"ADJ\" and token.dep_ == \"amod\":\n",
    "        head = token.head  # The noun modified by this adjective\n",
    "        if head.pos_ == \"NOUN\":\n",
    "            pairs.append((token.text, head.text))\n",
    "\n",
    "# Print results\n",
    "print(\"Adjective-Noun pairs:\")\n",
    "for adj, noun in pairs:\n",
    "    print(f\"{adj} -> {noun}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5f77266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy English model once globally (avoid reloading every call)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_adj_noun_pairs(sentence):\n",
    "    \"\"\"\n",
    "    Extract adjective-noun (amod) pairs from a sentence.\n",
    "    Returns a list of tuples: [(adj, noun), ...]\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    pairs = []\n",
    "\n",
    "    for token in doc:\n",
    "        # adjective modifying a noun (amod)\n",
    "        if token.pos_ == \"ADJ\" and token.dep_ == \"amod\":\n",
    "            head = token.head\n",
    "            if head.pos_ == \"NOUN\":\n",
    "                pairs.append((token.text, head.text))\n",
    "    \n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a684037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('inside', 'back'), ('solid', 'depression'), ('silver', 'depression'), ('small', 'photo'), ('High', 'quality')]\n"
     ]
    }
   ],
   "source": [
    "text = \"I think this locket is really pretty. The inside back is a solid silver depression and the front is a dome that is not solid (knotted). You could use it to store a small photo, lock of hair, etc but I use it when I need to carry medication with me. Closes securely. High quality & very pretty.\"\n",
    "\n",
    "pairs = extract_adj_noun_pairs(text)\n",
    "print(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ed819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fcfe241",
   "metadata": {},
   "source": [
    "## use less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "891350ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 lines\n",
      "Loaded 200000 lines\n",
      "Loaded 300000 lines\n",
      "Loaded 400000 lines\n",
      "Loaded 500000 lines\n",
      "Loaded 600000 lines\n",
      "Loaded 700000 lines\n",
      "Loaded 800000 lines\n",
      "Loaded 900000 lines\n",
      "Loaded 1000000 lines\n",
      "Loaded 1100000 lines\n",
      "Loaded 1200000 lines\n",
      "Loaded 1300000 lines\n",
      "Loaded 1400000 lines\n",
      "Loaded 1500000 lines\n",
      "Loaded 1600000 lines\n",
      "Loaded 1700000 lines\n",
      "Loaded 1800000 lines\n",
      "Loaded 1900000 lines\n",
      "Loaded 2000000 lines\n",
      "Loaded 2100000 lines\n",
      "Loaded 2200000 lines\n",
      "Loaded 2300000 lines\n",
      "Loaded 2400000 lines\n",
      "Loaded 2500000 lines\n",
      "Loaded 2600000 lines\n",
      "Loaded 2700000 lines\n",
      "Loaded 2800000 lines\n",
      "Loaded 2900000 lines\n",
      "Loaded 3000000 lines\n",
      "Loaded 3100000 lines\n",
      "Loaded 3200000 lines\n",
      "Loaded 3300000 lines\n",
      "Loaded 3400000 lines\n",
      "Loaded 3500000 lines\n",
      "Loaded 3600000 lines\n",
      "Loaded 3700000 lines\n",
      "Loaded 3800000 lines\n",
      "Loaded 3900000 lines\n",
      "Loaded 4000000 lines\n",
      "Loaded 4100000 lines\n",
      "Loaded 4200000 lines\n",
      "Loaded 4300000 lines\n",
      "Loaded 4400000 lines\n",
      "Loaded 4500000 lines\n",
      "Loaded 4600000 lines\n",
      "Loaded 4700000 lines\n",
      "Loaded 4800000 lines\n",
      "Loaded 4900000 lines\n",
      "Loaded 5000000 lines\n",
      "Loaded 5100000 lines\n",
      "Loaded 5200000 lines\n",
      "Loaded 5300000 lines\n",
      "Loaded 5400000 lines\n",
      "Loaded 5500000 lines\n",
      "Loaded 5600000 lines\n",
      "Loaded 5700000 lines\n",
      "Loaded 5800000 lines\n",
      "Loaded 5900000 lines\n",
      "Loaded 6000000 lines\n",
      "Loaded 6100000 lines\n",
      "Loaded 6200000 lines\n",
      "Loaded 6300000 lines\n",
      "Loaded 6400000 lines\n",
      "Loaded 6500000 lines\n",
      "Loaded 6600000 lines\n",
      "Loaded 6700000 lines\n",
      "Loaded 6800000 lines\n",
      "Loaded 6900000 lines\n",
      "Loaded 7000000 lines\n",
      "Loaded 7100000 lines\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         record = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m         records.append({\n\u001b[32m     11\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreviewText\u001b[39m\u001b[33m\"\u001b[39m: record.get(\u001b[33m\"\u001b[39m\u001b[33mreviewText\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     12\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33moverall\u001b[39m\u001b[33m\"\u001b[39m: record.get(\u001b[33m\"\u001b[39m\u001b[33moverall\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     13\u001b[39m         })\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m json.JSONDecodeError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:299\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp.read(),\n\u001b[32m    294\u001b[39m         \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m         parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloads\u001b[39m(s, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    300\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    301\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[33;03m    containing a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    303\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    331\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = r\"/mnt/d/acode/nlp/data/Electronics.jsonl\"\n",
    "\n",
    "records = []\n",
    "with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            records.append({\n",
    "                \"reviewText\": record.get(\"reviewText\", \"\"),\n",
    "                \"overall\": record.get(\"overall\", None)\n",
    "            })\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        # 控制内存：每 100,000 行保存一次\n",
    "        if (i + 1) % 100000 == 0:\n",
    "            print(f\"Loaded {i+1} lines\")\n",
    "            # 可以在这里先处理或写入文件\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6a68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 10,000,000 lines.\n",
      "Read 100,000 lines. Non-empty so far: 0\n",
      "Read 200,000 lines. Non-empty so far: 0\n",
      "Read 300,000 lines. Non-empty so far: 0\n",
      "Read 400,000 lines. Non-empty so far: 0\n",
      "Read 500,000 lines. Non-empty so far: 0\n",
      "Read 600,000 lines. Non-empty so far: 0\n",
      "Read 700,000 lines. Non-empty so far: 0\n",
      "Read 800,000 lines. Non-empty so far: 0\n",
      "Read 900,000 lines. Non-empty so far: 0\n",
      "Read 1,000,000 lines. Non-empty so far: 0\n",
      "\n",
      "Finished: total lines read = 1,000,000\n",
      "Non-empty reviewText = 0\n",
      "Records stored = 1,000,000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = r\"/mnt/d/acode/nlp/data/Electronics.jsonl\"\n",
    "\n",
    "SKIP = 10_000_000      # skip first 10 million lines\n",
    "MAX_READ = 1_000_000   # read next 1 million lines\n",
    "\n",
    "records = []\n",
    "total_read = 0\n",
    "non_empty = 0\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    # Skip lines safely\n",
    "    for _ in range(SKIP):\n",
    "        line = next(f, None)\n",
    "        if line is None:\n",
    "            print(\"File ended before SKIP. No more data.\")\n",
    "            break\n",
    "    print(f\"Skipped {SKIP:,} lines.\")\n",
    "\n",
    "    # Read next chunk\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= MAX_READ:\n",
    "            break\n",
    "\n",
    "        total_read += 1\n",
    "\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        review = record.get(\"reviewText\", None)\n",
    "        overall = record.get(\"overall\", None)\n",
    "\n",
    "        # Allow empty reviews first, just count\n",
    "        if review and review.strip():\n",
    "            non_empty += 1\n",
    "\n",
    "        records.append({\n",
    "            \"reviewText\": review,\n",
    "            \"overall\": overall\n",
    "        })\n",
    "\n",
    "        if (i + 1) % 100000 == 0:\n",
    "            print(f\"Read {i+1:,} lines. Non-empty so far: {non_empty:,}\")\n",
    "\n",
    "print(f\"\\nFinished: total lines read = {total_read:,}\")\n",
    "print(f\"Non-empty reviewText = {non_empty:,}\")\n",
    "print(f\"Records stored = {len(records):,}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d349888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reviewText': None, 'overall': None}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e039ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100,000 lines\n",
      "Loaded 200,000 lines\n",
      "Loaded 300,000 lines\n",
      "Loaded 400,000 lines\n",
      "Loaded 500,000 lines\n",
      "Loaded 600,000 lines\n",
      "Loaded 700,000 lines\n",
      "Loaded 800,000 lines\n",
      "\n",
      "Finished reading 826,108 lines.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = r\"/mnt/d/acode/amz/beauty/1/meta_Amazon_Fashion.jsonl\"\n",
    "\n",
    "MAX_READ = 1_000_000\n",
    "records = []\n",
    "total_read = 0\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= MAX_READ:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        records.append(record)\n",
    "        total_read += 1\n",
    "\n",
    "        if (i + 1) % 100000 == 0:\n",
    "            print(f\"Loaded {i+1:,} lines\")\n",
    "\n",
    "print(f\"\\nFinished reading {total_read:,} lines.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d44a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['main_category', 'title', 'average_rating', 'rating_number', 'features', 'description', 'price', 'images', 'videos', 'store', 'categories', 'details', 'parent_asin', 'bought_together']\n"
     ]
    }
   ],
   "source": [
    "if len(records) == 0:\n",
    "    print(\"records is empty. No data loaded.\")\n",
    "else:\n",
    "    print(\"Columns:\", list(records[0].keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 records:\n",
      "{'main_category': 'AMAZON FASHION', 'title': \"YUEDGE 5 Pairs Men's Moisture Control Cushioned Dry Fit Casual Athletic Crew Socks for Men (Blue, Size 9-12)\", 'average_rating': 4.6, 'rating_number': 16, 'features': [], 'description': [], 'price': None, 'images': [{'thumb': 'https://m.media-amazon.com/images/I/41+cCfaVOFS._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/41+cCfaVOFS._AC_.jpg', 'variant': 'MAIN', 'hi_res': 'https://m.media-amazon.com/images/I/81XlFXImFrS._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/41jBdP7etRS._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/41jBdP7etRS._AC_.jpg', 'variant': 'PT01', 'hi_res': 'https://m.media-amazon.com/images/I/61+yVkHHQ3S._AC_UL1200_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/41UGJiRe7UL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/41UGJiRe7UL._AC_.jpg', 'variant': 'PT02', 'hi_res': 'https://m.media-amazon.com/images/I/61vbh6sLR1L._AC_UL1200_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/41zb4GR-lWS._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/41zb4GR-lWS._AC_.jpg', 'variant': 'PT03', 'hi_res': 'https://m.media-amazon.com/images/I/71tRVQuan7S._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/612BT4t-uFL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/612BT4t-uFL._AC_.jpg', 'variant': 'PT04', 'hi_res': 'https://m.media-amazon.com/images/I/81BvTztKWGL._AC_UL1200_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/51ExLGv3QwL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/51ExLGv3QwL._AC_.jpg', 'variant': 'PT05', 'hi_res': 'https://m.media-amazon.com/images/I/71LytMHW9ML._AC_UL1200_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/313iU0xDEkS._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/313iU0xDEkS._AC_.jpg', 'variant': 'PT06', 'hi_res': 'https://m.media-amazon.com/images/I/71wJKMbj5cS._AC_UL1500_.jpg'}], 'videos': [], 'store': 'GiveGift', 'categories': [], 'details': {'Package Dimensions': '10.31 x 8.5 x 1.73 inches; 14.82 Ounces', 'Item model number': 'DHES5PM21DH12', 'Date First Available': 'February 12, 2021'}, 'parent_asin': 'B08BHN9PK5', 'bought_together': None}\n",
      "{'main_category': 'AMAZON FASHION', 'title': \"DouBCQ Women's Palazzo Lounge Wide Leg Casual Flowy Pants(Flower Mix Blue, XL)\", 'average_rating': 4.1, 'rating_number': 7, 'features': ['Drawstring closure', 'Machine Wash'], 'description': [], 'price': None, 'images': [{'thumb': 'https://m.media-amazon.com/images/I/515cR-ta1EL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/515cR-ta1EL._AC_.jpg', 'variant': 'MAIN', 'hi_res': 'https://m.media-amazon.com/images/I/91Z4G2jlFeL._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/51Dyk8PiO7L._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/51Dyk8PiO7L._AC_.jpg', 'variant': 'PT01', 'hi_res': 'https://m.media-amazon.com/images/I/91nZpeWHn-L._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/51MS48eV8XL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/51MS48eV8XL._AC_.jpg', 'variant': 'PT02', 'hi_res': 'https://m.media-amazon.com/images/I/91aCjCS6e0L._AC_UL1500_.jpg'}], 'videos': [], 'store': 'DouBCQ', 'categories': [], 'details': {'Package Dimensions': '15 x 10.2 x 0.4 inches; 9.59 Ounces', 'Item model number': 'Drop Crotch', 'Date First Available': 'February 5, 2021'}, 'parent_asin': 'B08R39MRDW', 'bought_together': None}\n",
      "{'main_category': 'AMAZON FASHION', 'title': \"Pastel by Vivienne Honey Vanilla Girls' Trapeze Dress with Easy Removable Label Large 9-10 Years Navy\", 'average_rating': 4.3, 'rating_number': 11, 'features': ['Zipper closure', 'Hand Wash Only'], 'description': [], 'price': None, 'images': [{'thumb': 'https://m.media-amazon.com/images/I/31GwmwNCdAL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/31GwmwNCdAL._AC_.jpg', 'variant': 'MAIN', 'hi_res': 'https://m.media-amazon.com/images/I/612-CtsBAvL._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/314fak19lKL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/314fak19lKL._AC_.jpg', 'variant': 'PT01', 'hi_res': 'https://m.media-amazon.com/images/I/61nnlxsYhZL._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/315u9+LVroL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/315u9+LVroL._AC_.jpg', 'variant': 'PT02', 'hi_res': 'https://m.media-amazon.com/images/I/613At4OGLOL._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/31nh+KU31cL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/31nh+KU31cL._AC_.jpg', 'variant': 'PT03', 'hi_res': 'https://m.media-amazon.com/images/I/51MZdXHAcPL._AC_UL1444_.jpg'}], 'videos': [], 'store': 'Pastel by Vivienne', 'categories': [], 'details': {'Is Discontinued By Manufacturer': 'No', 'Package Dimensions': '8.98 x 7.95 x 0.98 inches; 6.24 Ounces', 'Item model number': 'RJ-K140NA-LRG', 'Date First Available': 'November 11, 2018'}, 'parent_asin': 'B077KJHCJ4', 'bought_together': None}\n",
      "{'main_category': 'AMAZON FASHION', 'title': 'Mento Streamtail', 'average_rating': 2.0, 'rating_number': 1, 'features': ['Thermoplastic Rubber sole', 'High Density Premium Thickness Comfort Foam Footbed', 'Full Color Original Guy Harvey Artwork On Wavy Outsole', 'Soft Canvas Strap Lining with Embroidered Logo', 'Screen Printed Logo on Footbed', 'Lightweight Non-Marking EVA Outsole with Flex Grooves'], 'description': [\"Slip on the Women's Mento and you're ready to hit the beach. This thong sandal features canvas straps with a soft lining, a high density premium thickness comfort foam footbed and a lightweight non-marking EVA outsole with flex grooves. A full color digital print of Guy Harvey's artwork is featured on the wavy outsole.\"], 'price': 29.81, 'images': [{'thumb': 'https://m.media-amazon.com/images/I/31P-uHUUIXL._AC_US40_.jpg', 'large': 'https://m.media-amazon.com/images/I/31P-uHUUIXL._AC_.jpg', 'variant': 'MAIN', 'hi_res': 'https://m.media-amazon.com/images/I/61qmATFO2FL._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/41G-1W5k7EL._AC_US40_.jpg', 'large': 'https://m.media-amazon.com/images/I/41G-1W5k7EL._AC_.jpg', 'variant': 'FRNT', 'hi_res': 'https://m.media-amazon.com/images/I/6160QrWEfJL._AC_UL1310_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/41yhiAiCrBL._AC_US40_.jpg', 'large': 'https://m.media-amazon.com/images/I/41yhiAiCrBL._AC_.jpg', 'variant': 'BACK', 'hi_res': 'https://m.media-amazon.com/images/I/61eVvnbcjUL._AC_UL1237_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/31bXKbAKHSL._AC_US40_.jpg', 'large': 'https://m.media-amazon.com/images/I/31bXKbAKHSL._AC_.jpg', 'variant': 'BOTT', 'hi_res': 'https://m.media-amazon.com/images/I/71+eg7eJdML._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/31wjUX7o8YL._AC_US40_.jpg', 'large': 'https://m.media-amazon.com/images/I/31wjUX7o8YL._AC_.jpg', 'variant': 'TOPP', 'hi_res': 'https://m.media-amazon.com/images/I/71JRdvDhuWL._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/21cadRZ+01L._AC_US40_.jpg', 'large': 'https://m.media-amazon.com/images/I/21cadRZ+01L._AC_.jpg', 'variant': 'RGHT', 'hi_res': 'https://m.media-amazon.com/images/I/61hcldB99RL._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/31urvfwzRLL._AC_US40_.jpg', 'large': 'https://m.media-amazon.com/images/I/31urvfwzRLL._AC_.jpg', 'variant': 'PAIR', 'hi_res': 'https://m.media-amazon.com/images/I/71CdYWVZqPL._AC_UL1500_.jpg'}], 'videos': [], 'store': 'Guy Harvey', 'categories': [], 'details': {'Package Dimensions': '11.22 x 4.72 x 4.33 inches; 1.7 Pounds', 'Item model number': 'GHWMENTBGT-4152', 'Department': 'womens', 'Date First Available': 'November 5, 2019', 'Manufacturer': 'Guy Harvey', 'Country of Origin': 'China'}, 'parent_asin': 'B0811M2JG9', 'bought_together': None}\n",
      "{'main_category': 'AMAZON FASHION', 'title': \"RONNOX Women's 3-Pairs Bright Colored Calf Compression Tube Sleeves\", 'average_rating': 4.3, 'rating_number': 3032, 'features': ['Pull On closure', 'Size Guide: \"S\" fits calf 10-12 inches. \"M\" fits calf 12-14 inches. \"L\" fits calf 14-16 inches. \"XL\" fits calf 16-18 inches. The above size guide is for calf circumference the length of the sleeve unstretched is approx: S, 11 inch. M, 12 inch. L, 13 inch. XL, 14 inch', '3 Pairs: Styles and colors as seen in the picture. Choose between colorful sporty patterns & colored solids', 'Medium Compression: The solid styles have 16-20 mmHg Graduated Compression. The pattern styles have 12-14 mmHg Graduated Compression', 'Compression improves blood flow, aids with circulation, and keeps your feet energized. Great for running, athletic activities, & for nursing or standing all day', 'Helps in reducing swelling and aching in the legs. Great for pregnancy & flight travel or sitting long periods'], 'description': ['Ronnox Calf Sleeves - Allowing Your Body to Perform at Its Best!Some of the Ronnox Compression Socks Highlights:✔ Increase Endurance – Compression calf sleeves can reduce lactic acid and muscle fatigueallowing you to increase your endurance! Train harder, train better – and perform at your best.✔ Faster Recovery Time – Compression socks will aid in faster recovery time when worn for a few hours post workout.This is due to the increased blood flow to the calf muscles.✔ Reduce Swelling – Varicose veins, swollen ankles or swollen legs?The graduated premium compression can help to reduce swelling and assists your veins in getting blood to flow out of your legs and back to your heart!Ideal for long-haul flights or long journeys.✔ Minimize Cramps – Whether you get leg cramps during pregnancy or because your job requires being on your feet the entire day,these compression sleeves will help to reduce your leg cramps and muscle pain, helping you work and live better.General Features & Specifications:➤ Anatomically Designed to Fit Your Legs - No bunching or sliding down when walking, squatting or performing any exercise.Our calf sleeves will mold to the shape of your body.➤ Breathable Sweat-Wicking Design – The sweat-wicking breathable knee sleeve will regulate temperatureand ensure maximum comfort even during intense physical activity.➤ Soft Non-Irritating Neoprene Fabric – Instead of rough, scratchy calf sleeves, our fabric is softer, lighterand more comfortable than many others on the market.➤ Stretchable Elastic – This leg sleeve provides medium 15-20 hg graduated compression that won’t cause any blood clots or tighten around any veins.➤ Washable – Easy to clean, simply wash on a gentle cycle and hang to dry.➤ Sizes: Small / Medium / Large / Extra Large.➤ Colors: Hot Pink / Neon Green.'], 'price': 17.99, 'images': [{'thumb': 'https://m.media-amazon.com/images/I/51CqMDJOODL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/51CqMDJOODL._AC_.jpg', 'variant': 'MAIN', 'hi_res': 'https://m.media-amazon.com/images/I/91ub366PdKL._AC_UL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/417HN5YFVhL._AC_SR38,50_.jpg', 'large': 'https://m.media-amazon.com/images/I/417HN5YFVhL._AC_.jpg', 'variant': 'PT01', 'hi_res': 'https://m.media-amazon.com/images/I/61RpcNwx1SL._AC_UL1200_.jpg'}], 'videos': [{'title': \"HONEST Review: RONNOX Women's 3-Pairs Calf Tube Sleeves\", 'url': 'https://www.amazon.com/vdp/0dfab80ad5654f499f89ab2f68f61c9b?ref=dp_vse_rvc_0', 'user_id': '/shop/grillbuff'}, {'title': 'Calf Compression Sleeves for Men & Women', 'url': 'https://www.amazon.com/vdp/08ca5cc3c04d4391b9308ba719ecdb6b?ref=dp_vse_rvc_1', 'user_id': ''}], 'store': 'RONNOX', 'categories': [], 'details': {'Is Discontinued By Manufacturer': 'No', 'Package Dimensions': '7.7 x 4.3 x 1.8 inches; 6.38 Ounces', 'Department': 'womens', 'Date First Available': 'July 18, 2017', 'Manufacturer': 'RONNOX'}, 'parent_asin': 'B07SB2892S', 'bought_together': None}\n"
     ]
    }
   ],
   "source": [
    "if len(records) > 0:\n",
    "    print(\"\\nFirst 5 records:\")\n",
    "    for r in records[:5]:\n",
    "        print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d476e",
   "metadata": {},
   "source": [
    "## comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef93527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100,000 lines\n",
      "Loaded 200,000 lines\n",
      "Loaded 300,000 lines\n",
      "Loaded 400,000 lines\n",
      "Loaded 500,000 lines\n",
      "Loaded 600,000 lines\n",
      "Loaded 700,000 lines\n",
      "Loaded 800,000 lines\n",
      "Loaded 900,000 lines\n",
      "Loaded 1,000,000 lines\n",
      "\n",
      "Finished reading 1,000,000 lines into records2.\n",
      "\n",
      "Columns: ['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase']\n",
      "\n",
      "First 5 records:\n",
      "{'rating': 5.0, 'title': 'Pretty locket', 'text': 'I think this locket is really pretty. The inside back is a solid silver depression and the front is a dome that is not solid (knotted). You could use it to store a small photo, lock of hair, etc but I use it when I need to carry medication with me. Closes securely. High quality & very pretty.', 'images': [], 'asin': 'B00LOPVX74', 'parent_asin': 'B00LOPVX74', 'user_id': 'AGBFYI2DDIKXC5Y4FARTYDTQBMFQ', 'timestamp': 1578528394489, 'helpful_vote': 3, 'verified_purchase': True}\n",
      "{'rating': 5.0, 'title': 'A', 'text': 'Great', 'images': [], 'asin': 'B07B4JXK8D', 'parent_asin': 'B07B4JXK8D', 'user_id': 'AFQLNQNQYFWQZPJQZS6V3NZU4QBQ', 'timestamp': 1608426246701, 'helpful_vote': 0, 'verified_purchase': True}\n",
      "{'rating': 2.0, 'title': 'Two Stars', 'text': 'One of the stones fell out within the first 2 weeks of wearing it. Stones smaller than expected.', 'images': [], 'asin': 'B007ZSEQ4Q', 'parent_asin': 'B007ZSEQ4Q', 'user_id': 'AHITBJSS7KYUBVZPX7M2WJCOIVKQ', 'timestamp': 1432344828000, 'helpful_vote': 3, 'verified_purchase': True}\n",
      "{'rating': 1.0, 'title': 'Won’t buy again', 'text': 'Crappy socks. Money wasted. Bought to wear with my tieks. Don’t stay on feet well.', 'images': [], 'asin': 'B07F2BTFS9', 'parent_asin': 'B07F2BTFS9', 'user_id': 'AFVNEEPDEIH5SPUN5BWC6NKL3WNQ', 'timestamp': 1546289847095, 'helpful_vote': 2, 'verified_purchase': True}\n",
      "{'rating': 5.0, 'title': 'I LOVE these glasses', 'text': \"I LOVE these glasses!  They fit perfectly over my regular, rectangular glasses that I always have to wear in order to see.  I really appreciate having these pretty and stylish and sturdy sunglasses to wear over my glasses.  I'll buy these again and again whenever I need a new pair, which hopefully won't be too soon.\", 'images': [], 'asin': 'B00PKRFU4O', 'parent_asin': 'B00XESJTDE', 'user_id': 'AHSPLDNW5OOUK2PLH7GXLACFBZNQ', 'timestamp': 1439476166000, 'helpful_vote': 0, 'verified_purchase': True}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = r\"/mnt/d/acode/amz/beauty/Amazon_Fashion.jsonl\"\n",
    "\n",
    "MAX_READ = 1_000_000\n",
    "records2 = []\n",
    "total_read = 0\n",
    "\n",
    "# ===== Read first 1 million lines =====\n",
    "with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= MAX_READ:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "        \n",
    "        records2.append(record)\n",
    "        total_read += 1\n",
    "        \n",
    "        if (i + 1) % 100000 == 0:\n",
    "            print(f\"Loaded {i+1:,} lines\")\n",
    "\n",
    "print(f\"\\nFinished reading {total_read:,} lines into records2.\\n\")\n",
    "\n",
    "# ===== Print columns =====\n",
    "if len(records2) == 0:\n",
    "    print(\"records2 is empty.\")\n",
    "else:\n",
    "    print(\"Columns:\", list(records2[0].keys()))\n",
    "\n",
    "# ===== Print first 5 rows =====\n",
    "if len(records2) > 0:\n",
    "    print(\"\\nFirst 5 records:\")\n",
    "    for r in records2[:5]:\n",
    "        print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f26be72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100,000 rows\n",
      "Processed 200,000 rows\n",
      "Processed 300,000 rows\n",
      "Processed 400,000 rows\n",
      "Processed 500,000 rows\n",
      "Processed 600,000 rows\n",
      "Processed 700,000 rows\n",
      "Processed 800,000 rows\n",
      "Processed 900,000 rows\n",
      "Processed 1,000,000 rows\n"
     ]
    }
   ],
   "source": [
    "all_pairs = []   # 用来存 100 万条结果（顺序保留）\n",
    "\n",
    "for idx, rec in enumerate(records2):\n",
    "    sentence = rec.get(\"text\", \"\")\n",
    "    if not sentence:\n",
    "        all_pairs.append([])  # 保持位置一致（空）\n",
    "        continue\n",
    "    \n",
    "    pairs = extract_adj_noun_pairs(sentence)\n",
    "    all_pairs.append(pairs)\n",
    "\n",
    "    # 每 100k 行打印进度\n",
    "    if (idx + 1) % 100000 == 0:\n",
    "        print(f\"Processed {idx+1:,} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de571e77",
   "metadata": {},
   "source": [
    "## frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ecbe4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def count_adj_from_all_pairs(all_pair):\n",
    "    adjs = []\n",
    "\n",
    "    for group in all_pair:           # 每条评论\n",
    "        if not isinstance(group, (list, tuple)):\n",
    "            continue\n",
    "        \n",
    "        for row in group:           # 每条评论中的每个 pair\n",
    "            if not isinstance(row, (list, tuple)):\n",
    "                continue\n",
    "            if len(row) < 1:\n",
    "                continue\n",
    "            \n",
    "            adj = row[0]            # 第一个是 adj\n",
    "            \n",
    "            # 过滤 None、空字符串\n",
    "            if adj:\n",
    "                adjs.append(adj)\n",
    "\n",
    "    # 统计频率\n",
    "    counter = Counter(adjs)\n",
    "\n",
    "    df = pd.DataFrame(counter.items(), columns=[\"adj\", \"count\"])\n",
    "    df = df.sort_values(by=\"count\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b61325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     adj  count\n",
      "0   good  48160\n",
      "1  great  45992\n",
      "2  Great  41623\n",
      "3   nice  41506\n",
      "4  other  31910\n"
     ]
    }
   ],
   "source": [
    "df1 = count_adj_from_all_pairs(all_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "51ae164d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855\n"
     ]
    }
   ],
   "source": [
    "df1_over_100 = df1[df1[\"count\"] > 100]\n",
    "print(len(df1_over_100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca0eb600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load spaCy model\n",
    "# ---------------------------\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. noun 分类函数\n",
    "# ---------------------------\n",
    "def classify_noun(noun):\n",
    "    \"\"\"\n",
    "    Classify noun as PERSON / PRODUCT / OTHER\n",
    "    \"\"\"\n",
    "    doc = nlp(noun)\n",
    "\n",
    "    # rule 1: pronoun = person\n",
    "    if doc[0].pos_ == \"PRON\":\n",
    "        return \"PERSON\"\n",
    "\n",
    "    # rule 2: spaCy NER\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return \"PERSON\"\n",
    "        elif ent.label_ in [\"PRODUCT\", \"ORG\", \"WORK_OF_ART\", \"LAW\", \"EVENT\"]:\n",
    "            return \"PRODUCT\"\n",
    "\n",
    "    # rule 3: default\n",
    "    return \"OTHER\"\n",
    "\n",
    "# ---------------------------\n",
    "# 3. 清洗并扩展 pair 数据\n",
    "# ---------------------------\n",
    "def clean_and_expand_pairs_nested(pair_list):\n",
    "    cleaned = []\n",
    "\n",
    "    for group in pair_list:  \n",
    "        # group 是一个评论的所有 pairs\n",
    "        if not isinstance(group, (list, tuple)):\n",
    "            continue\n",
    "        \n",
    "        for row in group:      # row 是单个 (adj, noun)\n",
    "            if not isinstance(row, (list, tuple)):\n",
    "                continue\n",
    "            if len(row) < 2:\n",
    "                continue\n",
    "            \n",
    "            adj = row[0]\n",
    "            noun = row[1]\n",
    "\n",
    "            if not adj or not noun:\n",
    "                continue\n",
    "\n",
    "            category = classify_noun(noun)\n",
    "            cleaned.append([adj, noun, category])\n",
    "\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c807902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', 'quality', 'OTHER']\n",
      "['Great', 'quality', 'OTHER']\n",
      "['small', 'photo', 'OTHER']\n",
      "['solid', 'depression', 'OTHER']\n",
      "['silver', 'depression', 'OTHER']\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    [('Good', 'quality'), ('Great', 'quality')],\n",
    "    [('small', 'photo')],\n",
    "    [],\n",
    "    [('solid','depression'), ('silver','depression')]\n",
    "]\n",
    "\n",
    "cleaned = clean_and_expand_pairs_nested(test)\n",
    "\n",
    "for row in cleaned[:5]:\n",
    "    print(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f2de5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inside', 'back', 'OTHER']\n",
      "['solid', 'depression', 'OTHER']\n",
      "['silver', 'depression', 'OTHER']\n",
      "['small', 'photo', 'OTHER']\n",
      "['High', 'quality', 'OTHER']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned = clean_and_expand_pairs_nested(all_pairs)\n",
    "for row in cleaned[:5]:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8f4f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def adj_category_stats_filtered(cleaned, df1_over_100):\n",
    "    # Step 1: 提取需要筛选的 adj 列表\n",
    "    target_adjs = set(df1_over_100[\"adj\"].tolist())   # faster lookup\n",
    "    \n",
    "    # Step 2: 用 defaultdict 构建统计字典\n",
    "    stats = defaultdict(lambda: {\"person\": 0, \"product\": 0, \"other\": 0, \"total\": 0})\n",
    "\n",
    "    # Step 3: 遍历 cleaned，筛选 adj 并统计类别\n",
    "    for adj, noun, cat in cleaned:\n",
    "        if adj not in target_adjs:\n",
    "            continue\n",
    "        \n",
    "        stats[adj][\"total\"] += 1\n",
    "        \n",
    "        if cat == \"PERSON\":\n",
    "            stats[adj][\"person\"] += 1\n",
    "        elif cat == \"PRODUCT\":\n",
    "            stats[adj][\"product\"] += 1\n",
    "        else:\n",
    "            stats[adj][\"other\"] += 1\n",
    "\n",
    "    # Step 4: 转 DataFrame\n",
    "    rows = []\n",
    "    for adj, counts in stats.items():\n",
    "        total = counts[\"total\"]\n",
    "        rows.append([\n",
    "            adj,\n",
    "            total,\n",
    "            counts[\"person\"] / total if total else 0,\n",
    "            counts[\"product\"] / total if total else 0,\n",
    "            counts[\"other\"] / total if total else 0,\n",
    "            counts[\"person\"],\n",
    "            counts[\"product\"],\n",
    "            counts[\"other\"]\n",
    "        ])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"adj\", \"total\",\n",
    "        \"person_ratio\", \"product_ratio\", \"other_ratio\",\n",
    "        \"person_count\", \"product_count\", \"other_count\"\n",
    "    ])\n",
    "\n",
    "    # Step 5: 按 person_ratio 排序\n",
    "    df = df.sort_values(by=\"person_ratio\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "203c1fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           adj  total  person_ratio  product_ratio  other_ratio  person_count  \\\n",
      "0          Muy    622      0.192926       0.191318     0.615756           120   \n",
      "1       direct    222      0.135135       0.004505     0.860360            30   \n",
      "2          muy    145      0.124138       0.158621     0.717241            18   \n",
      "3       French    123      0.105691       0.008130     0.886179            13   \n",
      "4        harsh    159      0.075472       0.012579     0.911950            12   \n",
      "5        panty    173      0.075145       0.011561     0.913295            13   \n",
      "6      intense    150      0.066667       0.006667     0.926667            10   \n",
      "7       active    573      0.064572       0.003490     0.931937            37   \n",
      "8      Ordered    110      0.054545       0.027273     0.918182             6   \n",
      "9     vertical    186      0.053763       0.000000     0.946237            10   \n",
      "10        avid    204      0.049020       0.039216     0.911765            10   \n",
      "11     bifocal    178      0.044944       0.000000     0.955056             8   \n",
      "12      golden    228      0.039474       0.017544     0.942982             9   \n",
      "13         pet    158      0.037975       0.000000     0.962025             6   \n",
      "14      bright   3432      0.036422       0.007867     0.955711           125   \n",
      "15     unicorn    170      0.035294       0.029412     0.935294             6   \n",
      "16        busy    221      0.031674       0.000000     0.968326             7   \n",
      "17  mechanical    167      0.029940       0.011976     0.958084             5   \n",
      "18        rich    578      0.029412       0.036332     0.934256            17   \n",
      "19        dark   2990      0.027425       0.084615     0.887960            82   \n",
      "\n",
      "    product_count  other_count  \n",
      "0             119          383  \n",
      "1               1          191  \n",
      "2              23          104  \n",
      "3               1          109  \n",
      "4               2          145  \n",
      "5               2          158  \n",
      "6               1          139  \n",
      "7               2          534  \n",
      "8               3          101  \n",
      "9               0          176  \n",
      "10              8          186  \n",
      "11              0          170  \n",
      "12              4          215  \n",
      "13              0          152  \n",
      "14             27         3280  \n",
      "15              5          159  \n",
      "16              0          214  \n",
      "17              2          160  \n",
      "18             21          540  \n",
      "19            253         2655  \n"
     ]
    }
   ],
   "source": [
    "result_df = adj_category_stats_filtered(cleaned, df1_over_100)\n",
    "print(result_df.head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d1325fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_cleaned = pd.DataFrame(cleaned, columns=[\"adj\", \"noun\", \"category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a075fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"cleaned_pairs.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
