{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9585dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemuna/d1/nlpm/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/pkugoodspeed/nlpword2vecembeddingspretrained?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.46G/2.46G [00:58<00:00, 45.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/artemuna/.cache/kagglehub/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"pkugoodspeed/nlpword2vecembeddingspretrained\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6392e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNews-vectors-negative300.bin\n",
      "glove.6B.300d.txt\n",
      "glove.6B.200d.txt\n",
      "glove.6B.50d.txt\n",
      "glove.6B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/home/artemuna/.cache/kagglehub/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/versions/1\"\n",
    "\n",
    "# 列出文件\n",
    "for file in os.listdir(folder_path):\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d2cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_848/2081348066.py:11: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 原始 GloVe 文件路径\n",
    "glove_input_file = \"/home/artemuna/.cache/kagglehub/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/versions/1/glove.6B.300d.txt\"\n",
    "\n",
    "# 转换后的中间 word2vec 文件\n",
    "word2vec_output_file = \"/tmp/glove.6B.300d.word2vec.txt\"\n",
    "\n",
    "# 1️⃣ 先转换格式\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "# 2️⃣ 再加载为 gensim 的 KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a46de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/artemuna/.cache/kagglehub/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/versions/1/glove.6B.300d.txt\"\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9800075f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20842  , -0.019668 ,  0.063981 , -0.71403  , -0.21181  ,\n",
       "       -0.59283  , -0.15316  ,  0.044217 ,  0.63289  , -0.84821  ,\n",
       "       -0.21129  , -0.19763  ,  0.19029  , -0.56226  ,  0.27126  ,\n",
       "        0.23782  , -0.5189   , -0.24518  ,  0.035243 ,  0.096833 ,\n",
       "        0.24898  ,  0.71279  ,  0.038279 , -0.10514  , -0.4779   ,\n",
       "       -0.39515  , -0.27194  , -0.44428  ,  0.06113  , -0.2318   ,\n",
       "       -0.35901  , -0.18239  ,  0.035507 , -0.087719 , -1.0816   ,\n",
       "       -0.42521  ,  0.003224 , -0.45991  , -0.043462 , -0.39031  ,\n",
       "        0.519    ,  0.21139  , -0.25527  ,  1.1805   , -0.19041  ,\n",
       "       -0.12156  ,  0.034186 , -0.062316 ,  0.14421  , -0.53366  ,\n",
       "        0.47425  , -0.4471   ,  0.58047  ,  0.43578  ,  0.1321   ,\n",
       "       -0.095712 , -0.37182  , -0.013837 ,  0.20601  , -0.10099  ,\n",
       "        0.10685  , -0.33723  ,  0.10986  ,  0.34796  , -0.099839 ,\n",
       "        0.36942  , -0.52917  ,  0.12407  , -0.46127  , -0.38483  ,\n",
       "       -0.10114  , -0.17634  ,  0.37574  ,  0.16377  , -0.2198   ,\n",
       "       -0.26841  ,  0.84706  , -0.35619  , -0.083992 , -0.20276  ,\n",
       "       -0.56542  ,  0.19112  , -0.14134  , -0.7812   ,  0.69188  ,\n",
       "       -0.083628 , -0.54293  ,  0.16437  ,  0.037606 , -0.68896  ,\n",
       "       -0.68711  , -0.13367  , -0.4779   ,  0.20125  ,  0.085122 ,\n",
       "       -0.063865 , -0.17104  , -0.32432  , -0.17623  , -0.514    ,\n",
       "       -0.50289  ,  0.23204  , -0.11324  , -1.064    , -0.035359 ,\n",
       "       -0.5068   , -0.27118  , -0.16621  , -0.63016  ,  0.054252 ,\n",
       "       -0.048178 ,  0.29282  , -0.030666 , -0.24645  , -0.27084  ,\n",
       "       -0.42563  , -0.39171  ,  0.18428  , -0.017772 , -0.35334  ,\n",
       "       -0.49075  , -0.90782  ,  0.13872  , -0.76521  , -0.46318  ,\n",
       "       -0.32124  , -0.086228 ,  1.0448   , -0.39919  ,  0.69478  ,\n",
       "       -0.10377  ,  0.86715  ,  0.22742  ,  0.4384   ,  0.085767 ,\n",
       "       -0.22846  ,  0.4309   ,  0.064187 , -0.027926 , -0.093056 ,\n",
       "        0.65188  ,  0.59143  , -0.3376   , -0.37732  ,  0.0052212,\n",
       "        1.1193   , -0.23845  , -0.16029  ,  0.42877  , -0.16228  ,\n",
       "       -0.12202  , -0.1061   ,  0.015761 ,  0.022745 , -0.17734  ,\n",
       "       -0.091711 , -0.29158  ,  0.19034  , -0.35168  ,  0.27563  ,\n",
       "       -0.20577  ,  0.11472  , -0.34126  , -0.0065915,  0.14896  ,\n",
       "       -0.026762 ,  0.0019373,  0.53279  , -0.76088  ,  0.063085 ,\n",
       "       -0.72089  , -0.04128  , -0.96164  ,  0.020769 ,  0.16123  ,\n",
       "       -0.34342  ,  0.69713  , -0.16018  , -0.11701  , -0.070239 ,\n",
       "       -0.30774  ,  0.39741  ,  0.39994  , -0.678    ,  0.57684  ,\n",
       "       -0.48099  ,  0.59317  , -0.42262  ,  0.28613  , -0.26203  ,\n",
       "        0.052727 ,  0.61659  , -0.36801  , -0.28429  , -0.40054  ,\n",
       "       -0.30055  , -0.27444  , -0.045729 , -0.56105  ,  0.24176  ,\n",
       "        0.86631  , -0.83715  ,  0.13562  ,  0.26196  , -0.43055  ,\n",
       "        0.34558  ,  0.059441 ,  0.61845  ,  0.11837  , -0.019168 ,\n",
       "        0.47697  , -0.32465  , -0.15463  , -0.23556  , -0.64263  ,\n",
       "       -0.092156 , -0.19622  ,  0.40666  ,  0.18009  ,  0.094309 ,\n",
       "        0.046917 ,  0.26369  , -0.50727  ,  0.37491  , -0.66773  ,\n",
       "        0.35095  , -0.033835 ,  0.30534  ,  0.23166  ,  0.023526 ,\n",
       "       -0.68365  ,  0.26078  , -0.22526  , -0.2656   ,  0.59967  ,\n",
       "        0.2598   ,  0.36248  ,  0.15564  , -0.45549  ,  0.11153  ,\n",
       "       -0.33287  ,  0.081364 , -0.36989  , -0.25543  , -1.1628   ,\n",
       "       -0.14622  , -0.032971 , -0.55619  ,  0.47717  , -0.29021  ,\n",
       "        0.42688  ,  1.2397   , -0.81391  ,  0.21084  , -0.25426  ,\n",
       "       -0.08684  , -0.078412 ,  0.26035  ,  0.3281   , -0.23777  ,\n",
       "        0.05138  , -0.030247 , -0.15669  ,  0.057147 ,  0.33902  ,\n",
       "        0.12795  , -0.21468  , -0.75208  ,  0.41422  ,  0.0062719,\n",
       "       -0.52904  ,  0.92193  , -0.42179  , -0.69638  ,  0.074115 ,\n",
       "        0.19071  , -1.2031   , -0.081333 , -0.4914   , -0.22159  ,\n",
       "       -0.29876  ,  0.30094  ,  0.018634 ,  0.18786  , -0.45429  ,\n",
       "       -0.29296  ,  0.3695   , -0.24218  , -0.11803  ,  0.071775 ,\n",
       "        0.44026  , -0.59978  ,  0.45354  ,  0.17854  , -0.17155  ,\n",
       "        0.018811 , -0.62354  , -0.014163 ,  0.16799  , -0.064392 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b846ce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lovely', 0.8095278739929199),\n",
       " ('gorgeous', 0.767159104347229),\n",
       " ('wonderful', 0.6419878005981445),\n",
       " ('magnificent', 0.632170557975769),\n",
       " ('elegant', 0.6133942008018494),\n",
       " ('charming', 0.5836594700813293),\n",
       " ('pretty', 0.5694172978401184),\n",
       " ('beauty', 0.5587742328643799),\n",
       " ('beautifully', 0.5468562245368958),\n",
       " ('splendid', 0.5426493287086487)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"beautiful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7795298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8065858483314514),\n",
       " ('queen', 0.689616322517395),\n",
       " ('monarch', 0.5575491189956665),\n",
       " ('throne', 0.5565375089645386),\n",
       " ('princess', 0.5518684387207031),\n",
       " ('mother', 0.5142154693603516),\n",
       " ('daughter', 0.5133156776428223),\n",
       " ('kingdom', 0.5025345087051392),\n",
       " ('prince', 0.5017741322517395),\n",
       " ('elizabeth', 0.4908031225204468)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model[\"king\"] - model[\"man\"] + model[\"woman\"]\n",
    "model.most_similar(positive=[vector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6cb66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "product_adjs = [\n",
    "    \"national\",\n",
    "    \"dangerous\",\n",
    "    \"long\",\n",
    "    \"hot\",\n",
    "    \"public\",\n",
    "    \"whole\",\n",
    "    \"simple\",\n",
    "    \"hard\",\n",
    "    \"small\",\n",
    "    \"poor\",\n",
    "    \"large\",\n",
    "    \"now\",\n",
    "    \"private\",\n",
    "    \"different\",\n",
    "    \"high\",\n",
    "    \"good\",\n",
    "    \"awesome\",\n",
    "    \"great\"\n",
    "]\n",
    "\n",
    "# Define second group as h1\n",
    "human_adjs = [\n",
    "    \"excellent\",\n",
    "    \"current\",\n",
    "    \"real\",\n",
    "    \"amazing\",\n",
    "    \"low\",\n",
    "    \"lost\",\n",
    "    \"full\",\n",
    "    \"fantastic\",\n",
    "    \"special\",\n",
    "    \"beautiful\",\n",
    "    \"nice\",\n",
    "    \"right\",\n",
    "    \"available\",\n",
    "    \"wonderful\",\n",
    "    \"legal\",\n",
    "    \"local\",\n",
    "    \"fine\",\n",
    "    \"easy\",\n",
    "    \"political\",\n",
    "    \"old\",\n",
    "    \"close\",\n",
    "    \"strong\",\n",
    "    \"professional\",\n",
    "    \"busy\",\n",
    "    \"helpful\",\n",
    "    \"friendly\",\n",
    "    \"ready\",\n",
    "    \"pleasant\",\n",
    "    \"happy\",\n",
    "    \"militant\",\n",
    "    \"willing\",\n",
    "    \"young\",\n",
    "    \"junior\",\n",
    "    \"senior\",\n",
    "    \"able\",\n",
    "    \"concerned\",\n",
    "    \"pleased\",\n",
    "    \"sure\",\n",
    "    \"interested\",\n",
    "    \"glad\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9949c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def avg_vector(words, model):\n",
    "    vecs = [model[word] for word in words if word in model]\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "human_vec = avg_vector(human_adjs, model)\n",
    "product_vec = avg_vector(product_adjs, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5edf0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def classify_adj_by_prototype(adj, model, human_vec, product_vec):\n",
    "    if adj not in model:\n",
    "        return None\n",
    "    v = model[adj]\n",
    "    sim_to_human = 1 - cosine(v, human_vec)\n",
    "    sim_to_product = 1 - cosine(v, product_vec)\n",
    "    return (\"person\" if sim_to_human > sim_to_product else \"product\", sim_to_human, sim_to_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1d88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def classify_adj_by_prototype(adj, model, human_vec, product_vec):\n",
    "    if adj not in model:\n",
    "        return None\n",
    "    v = model[adj]\n",
    "    sim_to_human = 1 - cosine(v, human_vec)\n",
    "    sim_to_product = 1 - cosine(v, product_vec)\n",
    "    return (\"person\" if sim_to_human > sim_to_product else \"product\", sim_to_human, sim_to_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c026724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggressive ('product', np.float32(0.3962645), np.float32(0.3987099))\n",
      "plastic ('product', np.float32(0.22752416), np.float32(0.31885296))\n",
      "elegant ('person', np.float32(0.28935206), np.float32(0.25249743))\n",
      "compact ('product', np.float32(0.19993985), np.float32(0.26742613))\n",
      "warm ('person', np.float32(0.43100423), np.float32(0.40670824))\n",
      "sharp ('product', np.float32(0.3305828), np.float32(0.33514857))\n",
      "soft ('product', np.float32(0.37286717), np.float32(0.3960541))\n",
      "rigid ('product', np.float32(0.15141988), np.float32(0.22396594))\n"
     ]
    }
   ],
   "source": [
    "adjectives_to_test = [\"aggressive\", \"plastic\", \"elegant\", \"compact\", \"warm\", \"sharp\", \"soft\", \"rigid\"]\n",
    "\n",
    "for adj in adjectives_to_test:\n",
    "    print(adj, classify_adj_by_prototype(adj, model, human_vec, product_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b2250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for filtered_person_adjs.csv:\n",
      "  → classified as person: 289\n",
      "  → classified as product: 262\n",
      "  → ratio: {'person': 0.5245009074410163, 'product': 0.47549909255898365}\n",
      "\n",
      "Results for strong_product_adjs.csv:\n",
      "  → classified as person: 301\n",
      "  → classified as product: 565\n",
      "  → ratio: {'person': 0.34757505773672054, 'product': 0.6524249422632794}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Assumes the following variables are already defined:\n",
    "# model: pretrained word embedding model (e.g., GloVe)\n",
    "# human_vec: averaged vector for human adjectives\n",
    "# product_vec: averaged vector for product adjectives\n",
    "\n",
    "# Classify a given adjective based on cosine similarity to prototype vectors\n",
    "def classify_adj_by_prototype(adj, model, human_vec, product_vec):\n",
    "    if adj not in model:\n",
    "        return None\n",
    "    v = model[adj]\n",
    "    sim_to_human = 1 - cosine(v, human_vec)\n",
    "    sim_to_product = 1 - cosine(v, product_vec)\n",
    "    return \"person\" if sim_to_human > sim_to_product else \"product\"\n",
    "\n",
    "# Load the first column (adjective list) from a CSV file\n",
    "def load_adjectives_from_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df.iloc[:, 0].dropna().unique().tolist()\n",
    "\n",
    "# Classify a list of adjectives and compute class-wise proportions\n",
    "def classify_and_summarize(word_list, model, human_vec, product_vec):\n",
    "    classified = {\"person\": [], \"product\": []}\n",
    "    for word in word_list:\n",
    "        label = classify_adj_by_prototype(word, model, human_vec, product_vec)\n",
    "        if label:\n",
    "            classified[label].append(word)\n",
    "\n",
    "    total = len(classified[\"person\"]) + len(classified[\"product\"])\n",
    "    ratio = {\n",
    "        \"person\": len(classified[\"person\"]) / total if total > 0 else 0,\n",
    "        \"product\": len(classified[\"product\"]) / total if total > 0 else 0\n",
    "    }\n",
    "    return classified, ratio\n",
    "\n",
    "# File paths for adjective CSVs\n",
    "path_person_csv = \"filtered_person_adjs.csv\"\n",
    "path_product_csv = \"filtered_product_adjs.csv\"\n",
    "\n",
    "# Load adjective lists\n",
    "person_adjs = load_adjectives_from_csv(path_person_csv)\n",
    "product_adjs = load_adjectives_from_csv(path_product_csv)\n",
    "\n",
    "# Classify each list and compute ratios\n",
    "classified_person, ratio_person = classify_and_summarize(person_adjs, model, human_vec, product_vec)\n",
    "classified_product, ratio_product = classify_and_summarize(product_adjs, model, human_vec, product_vec)\n",
    "\n",
    "# Print classification results\n",
    "print(\"Results for filtered_person_adjs.csv:\")\n",
    "print(\"  → classified as person:\", len(classified_person[\"person\"]))\n",
    "print(\"  → classified as product:\", len(classified_person[\"product\"]))\n",
    "print(\"  → ratio:\", ratio_person)\n",
    "\n",
    "print(\"\\nResults for strong_product_adjs.csv:\")\n",
    "print(\"  → classified as person:\", len(classified_product[\"person\"]))\n",
    "print(\"  → classified as product:\", len(classified_product[\"product\"]))\n",
    "print(\"  → ratio:\", ratio_product)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5bbd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save classified_person to CSV\n",
    "pd.DataFrame({\n",
    "    \"adj\": classified_person[\"person\"] + classified_person[\"product\"],\n",
    "    \"classified_as\": [\"person\"] * len(classified_person[\"person\"]) + [\"product\"] * len(classified_person[\"product\"])\n",
    "}).to_csv(\"classified_person_adjs_by_vector.csv\", index=False)\n",
    "\n",
    "# Save classified_product to CSV\n",
    "pd.DataFrame({\n",
    "    \"adj\": classified_product[\"person\"] + classified_product[\"product\"],\n",
    "    \"classified_as\": [\"person\"] * len(classified_product[\"person\"]) + [\"product\"] * len(classified_product[\"product\"])\n",
    "}).to_csv(\"classified_product_adjs_by_vector.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44eb8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "\n",
    "# Function to classify and return scores\n",
    "def classify_adj_with_score(adj_list, model, human_vec, product_vec):\n",
    "    results = []\n",
    "    for word in adj_list:\n",
    "        if word not in model:\n",
    "            continue\n",
    "        v = model[word]\n",
    "        sim_person = 1 - cosine(v, human_vec)\n",
    "        sim_product = 1 - cosine(v, product_vec)\n",
    "        label = \"person\" if sim_person > sim_product else \"product\"\n",
    "        results.append({\n",
    "            \"adj\": word,\n",
    "            \"classified_as\": label,\n",
    "            \"sim_to_person\": sim_person,\n",
    "            \"sim_to_product\": sim_product\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Re-run classification with similarity scores\n",
    "df_person = classify_adj_with_score(person_adjs, model, human_vec, product_vec)\n",
    "df_product = classify_adj_with_score(product_adjs, model, human_vec, product_vec)\n",
    "\n",
    "# Save to CSV\n",
    "df_person.to_csv(\"classified_person_adjs_by_vector.csv\", index=False)\n",
    "df_product.to_csv(\"classified_product_adjs_by_vector.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a659561",
   "metadata": {},
   "source": [
    "## Embedddin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "967f8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_vec = human_vec - product_vec  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483c8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_score(word, model, direction_vec):\n",
    "    if word not in model:\n",
    "        return None\n",
    "    v = model[word]\n",
    "    # 单位投影长度（可正可负）\n",
    "    return np.dot(v, direction_vec) / np.linalg.norm(direction_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c8d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elegant', np.float32(-0.032249287)),\n",
       " ('warm', np.float32(-0.45854154)),\n",
       " ('sharp', np.float32(-0.6423682)),\n",
       " ('aggressive', np.float32(-0.7012519)),\n",
       " ('soft', np.float32(-0.9269208)),\n",
       " ('rigid', np.float32(-1.1526953)),\n",
       " ('compact', np.float32(-1.2540897)),\n",
       " ('plastic', np.float32(-1.7011349))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_scores = {adj: projection_score(adj, model, direction_vec)\n",
    "              for adj in adjectives_to_test if adj in model}\n",
    "\n",
    "\n",
    "sorted(adj_scores.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12623f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 6.2144\n",
      "P-value: 0.00000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === Step 1: load adjective lists from CSV ===\n",
    "path_person_csv = \"filtered_person_adjs.csv\"\n",
    "path_product_csv = \"filtered_product_adjs.csv\"\n",
    "\n",
    "person_adjs = pd.read_csv(path_person_csv).iloc[:, 0].dropna().unique().tolist()\n",
    "product_adjs = pd.read_csv(path_product_csv).iloc[:, 0].dropna().unique().tolist()\n",
    "\n",
    "# === Step 2: define projection scoring function ===\n",
    "def projection_score(word, model, direction_vec):\n",
    "    if word not in model:\n",
    "        return None\n",
    "    vec = model[word]\n",
    "    return np.dot(vec, direction_vec) / (np.linalg.norm(vec) * np.linalg.norm(direction_vec))\n",
    "\n",
    "# === Step 3: calculate scores ===\n",
    "person_scores = {\n",
    "    word: projection_score(word, model, direction_vec)\n",
    "    for word in person_adjs if word in model\n",
    "}\n",
    "\n",
    "product_scores = {\n",
    "    word: projection_score(word, model, direction_vec)\n",
    "    for word in product_adjs if word in model\n",
    "}\n",
    "\n",
    "# === Step 4: convert to DataFrames and sort ===\n",
    "df_person_scores = pd.DataFrame([\n",
    "    {\"adj\": word, \"projection_score\": score}\n",
    "    for word, score in person_scores.items()\n",
    "]).sort_values(\"projection_score\", ascending=False)\n",
    "\n",
    "df_product_scores = pd.DataFrame([\n",
    "    {\"adj\": word, \"projection_score\": score}\n",
    "    for word, score in product_scores.items()\n",
    "]).sort_values(\"projection_score\", ascending=False)\n",
    "\n",
    "# === Step 5: save to CSV ===\n",
    "df_person_scores.to_csv(\"projection_scores_person.csv\", index=False)\n",
    "df_product_scores.to_csv(\"projection_scores_product.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9fc3daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 6.2144\n",
      "P-value: 0.00000\n",
      "Mean (person list): -0.0634\n",
      "Mean (product list): -0.1007\n",
      "→ Adjectives in the person list have a higher average projection score.\n"
     ]
    }
   ],
   "source": [
    "# === Step 6: t-test comparison ===\n",
    "person_vals = list(person_scores.values())\n",
    "product_vals = list(product_scores.values())\n",
    "\n",
    "t_stat, p_value = ttest_ind(person_vals, product_vals, equal_var=False)\n",
    "\n",
    "mean_person = np.mean(person_vals)\n",
    "mean_product = np.mean(product_vals)\n",
    "\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.5f}\")\n",
    "print(f\"Mean (person list): {mean_person:.4f}\")\n",
    "print(f\"Mean (product list): {mean_product:.4f}\")\n",
    "\n",
    "if mean_person > mean_product:\n",
    "    print(\"→ Adjectives in the person list have a higher average projection score.\")\n",
    "elif mean_person < mean_product:\n",
    "    print(\"→ Adjectives in the product list have a higher average projection score.\")\n",
    "else:\n",
    "    print(\"→ Both lists have the same mean projection score.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
